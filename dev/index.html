<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>OpenAI.jl Documentation · OpenAI.jl Documentation</title><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>OpenAI.jl Documentation</a></span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>OpenAI.jl Documentation</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>OpenAI.jl Documentation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>OpenAI.jl Documentation</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/rory-linehan/OpenAI.jl/blob/main/docs/src/index.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="OpenAI.jl-Documentation"><a class="docs-heading-anchor" href="#OpenAI.jl-Documentation">OpenAI.jl Documentation</a><a id="OpenAI.jl-Documentation-1"></a><a class="docs-heading-anchor-permalink" href="#OpenAI.jl-Documentation" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="OpenAI.list_models-Tuple{String}" href="#OpenAI.list_models-Tuple{String}"><code>OpenAI.list_models</code></a> — <span class="docstring-category">Method</span></header><section><div><p>List models</p><p><strong>Arguments:</strong></p><ul><li><code>api_key::String</code>: OpenAI API key</li></ul><p>For additional details, visit https://platform.openai.com/docs/api-reference/models/list</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/rory-linehan/OpenAI.jl/blob/7e814474e2761ca44ee7646437ee44546daf42f9/src/OpenAI.jl#L142-L149">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OpenAI.retrieve_model-Tuple{String, String}" href="#OpenAI.retrieve_model-Tuple{String, String}"><code>OpenAI.retrieve_model</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Retrieve model</p><p><strong>Arguments:</strong></p><ul><li><code>api_key::String</code>: OpenAI API key</li><li><code>model_id::String</code>: Model id</li></ul><p>For additional details, visit https://platform.openai.com/docs/api-reference/models/retrieve</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/rory-linehan/OpenAI.jl/blob/7e814474e2761ca44ee7646437ee44546daf42f9/src/OpenAI.jl#L154-L162">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OpenAI.create_completion-Tuple{String, String}" href="#OpenAI.create_completion-Tuple{String, String}"><code>OpenAI.create_completion</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Create completion</p><p><strong>Arguments:</strong></p><ul><li><code>api_key::String</code>: OpenAI API key</li><li><code>model_id::String</code>: Model id</li></ul><p><strong>Keyword Arguments (check the OpenAI docs for the exhaustive list):</strong></p><ul><li><code>temperature::Float64=1.0</code>: What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or top_p but not both.</li><li><code>top_p::Float64=1.0</code>: An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or temperature but not both.</li></ul><p>For more details about the endpoint and additional arguments, visit https://platform.openai.com/docs/api-reference/completions </p><p><strong>HTTP.request keyword arguments:</strong></p><ul><li><code>http_kwargs::NamedTuple=NamedTuple()</code>: Keyword arguments to pass to HTTP.request (e. g., <code>http_kwargs=(connection_timeout=2,)</code> to set a connection timeout of 2 seconds).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/rory-linehan/OpenAI.jl/blob/7e814474e2761ca44ee7646437ee44546daf42f9/src/OpenAI.jl#L167-L182">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OpenAI.create_chat" href="#OpenAI.create_chat"><code>OpenAI.create_chat</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Create chat</p><p><strong>Arguments:</strong></p><ul><li><code>api_key::String</code>: OpenAI API key</li><li><code>model_id::String</code>: Model id</li><li><code>messages::Vector</code>: The chat history so far.</li><li><code>streamcallback=nothing</code>: Function to call on each chunk (delta) of the chat response in streaming mode.</li></ul><p><strong>Keyword Arguments (check the OpenAI docs for the exhaustive list):</strong></p><ul><li><code>temperature::Float64=1.0</code>: What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or top_p but not both.</li><li><code>top_p::Float64=1.0</code>: An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or temperature but not both.</li></ul><p>!!! note: do not use <code>stream=true</code> option here, instead use the <code>streamcallback</code> keyword argument (see the relevant section below).</p><p>For more details about the endpoint and additional arguments, visit https://platform.openai.com/docs/api-reference/chat</p><p><strong>HTTP.request keyword arguments:</strong></p><ul><li><code>http_kwargs::NamedTuple=NamedTuple()</code>: Keyword arguments to pass to HTTP.request (e. g., <code>http_kwargs=(connection_timeout=2,)</code> to set a connection timeout of 2 seconds).</li></ul><p><strong>Example:</strong></p><pre><code class="language-julia hljs">julia&gt; CC = create_chat(&quot;..........&quot;, &quot;gpt-3.5-turbo&quot;, 
    [Dict(&quot;role&quot; =&gt; &quot;user&quot;, &quot;content&quot;=&gt; &quot;What is the OpenAI mission?&quot;)]
);

julia&gt; CC.response.choices[1][:message][:content]
&quot;

The OpenAI mission is to create safe and beneficial artificial intelligence (AI) that can help humanity achieve its full potential. The organization aims to discover and develop technical approaches to AI that are safe and aligned with human values. OpenAI believes that AI can help to solve some of the world&#39;s most pressing problems, such as climate change, disease, inequality, and poverty. The organization is committed to advancing research and development in AI while ensuring that it is used ethically and responsibly.&quot;</code></pre><p><strong>Streaming</strong></p><p>When a function that takes a single <code>String</code> as an argument is passed in the <code>streamcallback</code> argument, a request will be made in in streaming mode. The <code>streamcallback</code> callback will be called on every line of the streamed response. Here we use a callback that prints out the current time to demonstrate how different parts of the response are received at different times. </p><p>The response body will reflect the chunked nature of the response, so some reassembly will be required to recover the full message returned by the API.</p><pre><code class="language-julia hljs">julia&gt; CC = create_chat(key, &quot;gpt-3.5-turbo&quot;, 
           [Dict(&quot;role&quot; =&gt; &quot;user&quot;, &quot;content&quot;=&gt; &quot;What continent is New York in? Two word answer.&quot;)],
       streamcallback = x-&gt;println(Dates.now()));
2023-03-27T12:34:50.428
2023-03-27T12:34:50.524
2023-03-27T12:34:50.524
2023-03-27T12:34:50.524
2023-03-27T12:34:50.545
2023-03-27T12:34:50.556
2023-03-27T12:34:50.556

julia&gt; map(r-&gt;r[&quot;choices&quot;][1][&quot;delta&quot;], CC.response)
5-element Vector{JSON3.Object{Base.CodeUnits{UInt8, SubString{String}}, SubArray{UInt64, 1, Vector{UInt64}, Tuple{UnitRange{Int64}}, true}}}:
 {
   &quot;role&quot;: &quot;assistant&quot;
}
 {
   &quot;content&quot;: &quot;North&quot;
}
 {
   &quot;content&quot;: &quot; America&quot;
}
 {
   &quot;content&quot;: &quot;.&quot;
}
 {}</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/rory-linehan/OpenAI.jl/blob/7e814474e2761ca44ee7646437ee44546daf42f9/src/OpenAI.jl#L187-L257">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OpenAI.create_edit-Tuple{String, String, String}" href="#OpenAI.create_edit-Tuple{String, String, String}"><code>OpenAI.create_edit</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Create edit</p><p><strong>Arguments:</strong></p><ul><li><code>api_key::String</code>: OpenAI API key</li><li><code>model_id::String</code>: Model id (e.g. &quot;text-davinci-edit-001&quot;)</li><li><code>instruction::String</code>: The instruction that tells the model how to edit the prompt.</li><li><code>input::String</code> (optional): The input text to use as a starting point for the edit.</li><li><code>n::Int</code> (optional): How many edits to generate for the input and instruction.</li></ul><p><strong>Keyword Arguments:</strong></p><ul><li><code>http_kwargs::NamedTuple</code> (optional): Keyword arguments to pass to HTTP.request.</li></ul><p>For additional details about the endpoint, visit https://platform.openai.com/docs/api-reference/edits</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/rory-linehan/OpenAI.jl/blob/7e814474e2761ca44ee7646437ee44546daf42f9/src/OpenAI.jl#L263-L277">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OpenAI.create_embeddings" href="#OpenAI.create_embeddings"><code>OpenAI.create_embeddings</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Create embeddings</p><p><strong>Arguments:</strong></p><ul><li><code>api_key::String</code>: OpenAI API key</li><li><code>input</code>: The input text to generate the embedding(s) for, as String or array of tokens.   To get embeddings for multiple inputs in a single request, pass an array of strings   or array of token arrays. Each input must not exceed 8192 tokens in length.</li><li><code>model_id::String</code>: Model id. Defaults to text-embedding-ada-002.</li></ul><p><strong>Keyword Arguments:</strong></p><ul><li><code>http_kwargs::NamedTuple</code>: Optional. Keyword arguments to pass to HTTP.request.</li></ul><p>For additional details about the endpoint, visit https://platform.openai.com/docs/api-reference/embeddings</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/rory-linehan/OpenAI.jl/blob/7e814474e2761ca44ee7646437ee44546daf42f9/src/OpenAI.jl#L282-L296">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="OpenAI.create_images" href="#OpenAI.create_images"><code>OpenAI.create_images</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Create images</p><p><strong>Arguments:</strong></p><ul><li><code>api_key::String</code>: OpenAI API key</li><li><code>prompt</code>: The input text to generate the image(s) for, as String or array of tokens.</li><li><code>n</code>::Integer Optional. The number of images to generate. Must be between 1 and 10.</li><li><code>size</code>::String. Optional. Defaults to 1024x1024. The size of the generated images. Must be one of 256x256, 512x512, or 1024x1024.</li></ul><p><strong>Keyword Arguments:</strong></p><ul><li><code>http_kwargs::NamedTuple</code>: Optional. Keyword arguments to pass to HTTP.request.</li><li><code>response_format</code>::String: Optional. Defaults to &quot;url&quot;. The format of the response. Must be one of &quot;url&quot; or &quot;b64_json&quot;.</li></ul><p>For additional details about the endpoint, visit https://platform.openai.com/docs/api-reference/images/create</p><p><strong>once the request is made,</strong></p><p>download like this:  download(r.response[&quot;data&quot;][begin][&quot;url&quot;], &quot;image.png&quot;)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/rory-linehan/OpenAI.jl/blob/7e814474e2761ca44ee7646437ee44546daf42f9/src/OpenAI.jl#L301-L319">source</a></section></article></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Saturday 15 April 2023 20:35">Saturday 15 April 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
